{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract VCF info (overlapping vcf)\n",
    "os.chdir(\"/Charles/project/ASm6A/ASm6A/common_ASm6A/totaltissues/by_sample/overlap_peak/reorder/\")\n",
    "result_dir = \"overlap_vcf/\"\n",
    "os.system(\"mkdir -p %s\" % result_dir)\n",
    "ind_dict = {\n",
    "            \"ind1\": ['brain_IP_1', 'heart_IP_1', 'liver_IP_1'],  \n",
    "            \"ind2\": ['brain_IP_2', 'heart_IP_2', 'placenta_IP_2', 'kidney_IP_2', 'liver_IP_2'],  \n",
    "            \"ind3\": ['brain_IP_3', 'heart_IP_3', 'liver_IP_3', 'kidney_IP_3'], \n",
    "            \"ind4\": ['stomach_IP_4', 'muscle_IP_4', 'lung_IP_4', 'kidney_IP_4', 'placenta_IP_4'], \n",
    "            \"ind5\": ['stomach_IP_5', 'muscle_IP_5', 'lung_IP_5'], \n",
    "            \"ind6\": ['placenta_IP_6'],\n",
    "            \"ind7\": ['Adipose-1-1', 'Adrenal_gland-1-1', 'Aorta-1-1', 'Heart-1-1', 'Skin-1-1', 'Spleen-1-1'], \n",
    "            \"ind8\": ['Lung-2-1', 'Lung-2-4', 'Spleen-2-1', 'Tongue-2-1', 'Urinary_bladder-2-1'], \n",
    "            \"ind9\": ['Appendix-3-2', 'Colon-3-2', 'Esophagus-3-2', 'Muscle-3-2', 'Spleen-3-2'],\n",
    "            \"ind10\": ['Aorta-4-2', 'Esophagus-4-2', 'Heart-4-2', 'Jejunum-4-2', 'Liver-4-2','Lung-4-2','Lung-4-4','Prostate-4-2','Rectum-4-2','Skin-4-2','Stomach-4-2','Testis-4-2','Thyroid_gland-4-2','Urinary_bladder-4-2'],\n",
    "            \"ind11\": ['Appendix-5-3', 'Brainstem-5-3', 'Cerebellum-5-3', 'Cerebrum-5-3', 'Duodenum-5-3', 'Hypothalamus-5-3','Jejunum-5-3','Muscle-5-3','Rectum-5-3','Stomach-5-3','Thyroid_gland-5-3','Trachea-5-3','Urinary_bladder-5-3'], \n",
    "            \"ind12\": ['Cerebrum-6-3'],\n",
    "            \"ind13\": ['Cerebellum-7-4'],\n",
    "            \"ind14\": ['FrontalCortex_1','Cerebellum_1','Heart_1','Liver_1','Lung_1','Kidney_1','Spleen_1'],\n",
    "            \"ind15\": ['FrontalCortex_2','Cerebellum_2','Heart_2','Liver_2','Kidney_2','Spleen_2','Muscle_1'],\n",
    "            \"ind16\": ['FrontalCortex_3','Cerebellum_3','Heart_3','Liver_3','Lung_2','Muscle_2'],\n",
    "            \"ind17\": ['Muscle_3'],\n",
    "            \"ind18\": ['Lung_3','Kidney_3','Spleen_3']\n",
    "           }\n",
    "vcf_dir = \"/Charles/project/ASm6A/by_ind/SNP_calling/vcf_dir/rm_repeat_editing/overlap_dbsnp/\"\n",
    "vcf_list = glob.glob(\"%s/ind*_gatk.vcf\" % vcf_dir)\n",
    "with open(\"overlap.sh\", 'w') as fw:\n",
    "    for vcf in vcf_list:\n",
    "        p = os.path.basename(vcf).split(\"_gatk.vcf\")[0]\n",
    "        sample_list = ind_dict[p]\n",
    "        for sample in sample_list:\n",
    "            bed = \"%s.bed\" % sample\n",
    "            res = os.path.join(result_dir, \"%s.txt\" % sample)\n",
    "#             os.system(\"bedtools intersect -a %s -b %s -wa -wb > %s\" % (bed, vcf, res))\n",
    "            fw.write(\"bedtools intersect -a %s -b %s -wa -wb > %s\\n\" % (bed, vcf, res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select candidate SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tag SNP appeared in multiple samples\n",
    "info_dir = \"/Charles/project/ASm6A/ASm6A/common_ASm6A/totaltissues/by_sample/overlap_peak/reorder/overlap_vcf/\"\n",
    "\n",
    "def group_snp(df):\n",
    "    joint_snp = \"@\".join(df['SNP'].tolist())\n",
    "    df = pd.DataFrame(np.array([[df.iloc[0,0], df.iloc[0,1], df.iloc[0,2], joint_snp]]))\n",
    "    return df\n",
    "\n",
    "def reform_file(txt): # ASm6A + Peak + SNP\n",
    "    sample = os.path.basename(txt).split(\".txt\")[0]\n",
    "    df = pd.read_table(txt, header=None)\n",
    "    df['term'] = df.iloc[:,5] + \":\" + df.iloc[:,7].astype(str)\n",
    "    df['AR'] = df.iloc[:,8].str.split(\";\").str[1]\n",
    "    df['peak'] = df.iloc[:,0] + \":\" + df.iloc[:,1].astype(str) + \"-\" + df.iloc[:,2].astype(str)\n",
    "    df['SNP'] = df.iloc[:,11] + \":\" + df.iloc[:,12].astype(str) + \"-\" + df.iloc[:,20].str.split(\":\").str[0]\n",
    "    df = df[['term', 'AR', 'peak', 'SNP']]\n",
    "    ## merge SNP into one row for each peak\n",
    "    df = df.groupby(['term', 'AR', 'peak'], as_index=False).apply(group_snp)\n",
    "    df.columns = ['term', 'AR', 'peak', 'SNP']\n",
    "    df['value'] = sample + \";\" + df['AR'] + \";\" + df['peak'] + \";\" + df['SNP']\n",
    "    return df[['term', 'value']]\n",
    "\n",
    "bed_list, df_list, term_dict = glob.glob(\"%s/*.txt\" % info_dir), [], {}\n",
    "for bed in bed_list:\n",
    "    df_list.append(reform_file(bed))\n",
    "df = pd.concat(df_list)\n",
    "\n",
    "def reform_dict(in_dict):\n",
    "    out_dict = {}\n",
    "    for term, value_list in in_dict.items():\n",
    "        sample_list = [value.split(\";\")[0] for value in value_list]\n",
    "        ar_list     = [value.split(\";\")[1] for value in value_list]\n",
    "        peak_list   = [value.split(\";\")[2] for value in value_list]\n",
    "        snp_list    = [value.split(\";\")[3] for value in value_list]\n",
    "        out_dict[term] = {\"sample\": sample_list, \"AR\": ar_list, \"peak\": peak_list, \"SNP\": snp_list}\n",
    "    return out_dict\n",
    "\n",
    "for i, values in df.iterrows():\n",
    "    term_dict[values['term']] = term_dict.get(values['term'], []) + [values['value']]\n",
    "term_dict = reform_dict(term_dict)\n",
    "print(term_dict['chr1:6695123'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Candidate SNPs\n",
    "#### Extract SNP list contained in m6A peaks which contain ASm6As\n",
    "#### m6A peaks: the regions within which to search for candidate functional SNPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Charles/project/ASm6A/ASm6A/withPeak/\")\n",
    "result_dir = \"/Charles/project/ASm6A/ASm6A/functional_ASm6A/candidateSNP/\"\n",
    "os.system(\"mkdir -p %s\" % result_dir)\n",
    "vcf_dir = \"/Charles/project/ASm6A/corrected_vcf/vcf/rename/\"\n",
    "\n",
    "bed_list = glob.glob(\"*.bed\")\n",
    "for bed in bed_list:\n",
    "    res = os.path.join(result_dir, os.path.basename(bed))\n",
    "    df = pd.read_table(bed, header=None)\n",
    "    df = df.iloc[:,6:-1]\n",
    "    df.to_csv(res, sep=\"\\t\", header=False, index=False)\n",
    "    ### overlap vcf\n",
    "    p = os.path.basename(bed).split(\".bed\")[0]\n",
    "    vcf = os.path.join(vcf_dir, \"%s_gatk.vcf\"%p)\n",
    "    tag_vcf = os.path.join(result_dir, bed.replace(\".bed\", \".vcf\"))\n",
    "    os.system(\"bedtools intersect -a %s -b %s -wa -wb > %s\" % (vcf, res, tag_vcf))\n",
    "    os.remove(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### reformat candidate SNP and peak\n",
    "os.chdir(\"/Charles/project/ASm6A/ASm6A/functional_ASm6A/candidateSNP/\")\n",
    "vcf_list = glob.glob(\"*.vcf\")\n",
    "result_dir = \"reformat/\"\n",
    "os.system(\"mkdir -p %s\" % result_dir)\n",
    "\n",
    "for vcf in vcf_list:\n",
    "    sample = vcf.split(\".vcf\")[0]\n",
    "    df = pd.read_table(vcf, sep=\"\\t\", header=None)\n",
    "    df['m6Apeak'] = df.iloc[:,-4] + \":\" + df.iloc[:,-3].astype(str) + \"-\" + df.iloc[:,-2].astype(str)\n",
    "    df['candidateSNP'] = df.iloc[:,0]+\":\"+df.iloc[:,1].astype(str)\n",
    "    df['SNP_info'] = df.iloc[:,2]+\":\"+df.iloc[:,3]+\":\"+df.iloc[:,4]\n",
    "    df['genotype'] = df.iloc[:,9].astype(str).str.split(\":\").str[0]\n",
    "    df['alleleReads'] = df.iloc[:,9].astype(str).str.split(\":\").str[1]\n",
    "    df['sample'] = sample\n",
    "    result_file = os.path.join(result_dir, vcf.replace(\".vcf\", \".txt\"))\n",
    "    df = df[['candidateSNP','genotype','SNP_info','alleleReads','m6Apeak','sample']].drop_duplicates()\n",
    "    df.to_csv(result_file,sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select tagSNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/Charles/project/ASm6A/ASm6A/withPeak/\")\n",
    "bed_list = glob.glob(\"*.bed\")\n",
    "print(len(bed_list))\n",
    "result_dir = \"/Charles/project/ASm6A/ASm6A/functional_ASm6A/tagSNP/\"\n",
    "os.system(\"mkdir -p %s\" % result_dir)\n",
    "\n",
    "for bed in bed_list:\n",
    "    sample = bed.split(\".bed\")[0]\n",
    "    df = pd.read_table(bed, header=None)\n",
    "    df['tagSNP'] = df.iloc[:,0] + \":\" + df.iloc[:,2].astype(str)\n",
    "    df['allelicRatio'] = df.iloc[:,3].str.split(\";\").str[1]\n",
    "    df['mark'] = df.iloc[:,3].str.split(\";\").str[2]\n",
    "    df['m6Apeak'] = df.iloc[:,6] + \":\" + df.iloc[:,7].astype(str) + \"-\" + df.iloc[:,8].astype(str)\n",
    "    df['sample'] = sample\n",
    "    df = df[['tagSNP', 'allelicRatio', 'mark', 'm6Apeak', 'sample']].drop_duplicates()\n",
    "    result_file = os.path.join(result_dir, bed.replace(\".bed\", \".txt\"))\n",
    "    df.to_csv(result_file, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a unit m6A peak pool (90 samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "##############################################################################\n",
    "############## !!!!!!!!!!!!!  skip !!!!!!!!!!!!!!!!!!#########################\n",
    "#### define unified peak region\n",
    "#### for each tagSNP, combine the m6A peaks in the corresponding individuals\n",
    "##############################################################################\n",
    "## step 1: pick out tagSNP (total 90 samples)\n",
    "tagSNP = \"/Charles/project/ASm6A/ASm6A/functional_ASm6A/tagSNP/combined/totalSample_tagSNP.txt\"\n",
    "df_tagSNP = pd.read_table(tagSNP, header=None)\n",
    "df_tagSNP.columns = [\"tagSNP\", \"AR\", \"mark\", \"peak\", \"sample\"]\n",
    "# tagSNP_list = list(set(df_tagSNP.iloc[:,0].tolist()))\n",
    "# print(df_tagSNP.head())\n",
    "# count_dir = \"/Charles/project/ASm6A/Hypothesis_test/ASm6A/rename/\"\n",
    "## step 2: select only one cooresponding m6A peak randomly\n",
    "## potential problems (one m6A peak contains two tagSNPs) --- Not yet considered \n",
    "tagSNP_dict = {}\n",
    "for i, values in df_tagSNP.iterrows():\n",
    "    tagSNP_dict[values['tagSNP']] = tagSNP_dict.get(values['tagSNP'], []) + [values['peak']]\n",
    "peak_dict = {}\n",
    "for tagSNP, peak_list in tagSNP_dict.items():\n",
    "    peak_dict[tagSNP] = random.sample(peak_list, 1)[0]\n",
    "# print(peak_dict)\n",
    "## step 3: pick out candidate SNPs according to the m6A peak\n",
    "candSNP=\"/Charles/project/ASm6A/ASm6A/functional_ASm6A/candidateSNP/reformat/combined/totalSample_candidateSNP.txt\"\n",
    "df_cand = pd.read_table(candSNP)\n",
    "ar = \"/Charles/project/ASm6A/Hypothesis_test/ASm6A/rename/combined/totalSample_SNP.txt\"\n",
    "df_ar = pd.read_table(ar)\n",
    "\n",
    "def pick_out_candidateSNP(m6A_peak, tagSNP):\n",
    "    df = df_cand[df_cand['m6Apeak'] == m6A_peak]\n",
    "    df['SNP'] = tagSNP ### as a condition for filtering\n",
    "#     candSNP_samples = df['sample'].tolist()\n",
    "    ### two conditions need to be met\n",
    "    ### 1. tagSNP position; 2. candidate SNP sample\n",
    "    df_merge = df.merge(df_ar, on=['sample', 'SNP'])\n",
    "    return df_merge\n",
    "\n",
    "df_list = []\n",
    "for tagSNP, peak in peak_dict.items():\n",
    "    df = pick_out_candidateSNP(peak, tagSNP)\n",
    "#     df['tagSNP'] = df['SNP']\n",
    "#     del df['SNP']\n",
    "#     print(df.head())\n",
    "    df_list.append(df)\n",
    "df = pd.concat(df_list)\n",
    "df.to_csv(\"/Charles/project/ASm6A/ASm6A/functional_ASm6A/matching_data/test_for_functionASm6A.txt\",sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matching candidateSNPs and tagSNPs across individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagSNP_dir = \"/Charles/project/ASm6A/ASm6A/functional_ASm6A/tagSNP/\"\n",
    "candidateSNP_dir = \"/Charles/project/ASm6A/ASm6A/functional_ASm6A/candidateSNP/reformat/\"\n",
    "result_dir = \"/Charles/project/ASm6A/ASm6A/functional_ASm6A/matching_data/\"\n",
    "os.system(\"mkdir -p %s\" % result_dir)\n",
    "####\n",
    "tagSNP_list = glob.glob(\"%s/*.txt\" % tagSNP_dir)\n",
    "for tagSNP in tagSNP_list:\n",
    "    candidateSNP = os.path.joino(candidateSNP_dir, os.path.basename(tagSNP))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate genotype and allele depth dict across 90 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24,8\n",
      "3,5597\n"
     ]
    }
   ],
   "source": [
    "info_dir = \"/Charles/project/ASm6A/corrected_vcf/vcf/rename/extract_info/\"\n",
    "vcf_list = glob.glob(\"%s/*.vcf\" % info_dir)\n",
    "info_dict = {} # \n",
    "for vcf in vcf_list:\n",
    "    sample_n = os.path.basename(vcf).split(\"_gatk.vcf\")[0]\n",
    "    info_dict[sample_n] = {\"heter\": {}, \"homo\": {}}\n",
    "for vcf in vcf_list:   \n",
    "    sample_n = os.path.basename(vcf).split(\"_gatk.vcf\")[0]\n",
    "    df = pd.read_table(vcf)\n",
    "    #### filter based on read depth\n",
    "    df['refCount'] = df['GEN[*].AD'].str.split(\",\").str[0].astype(int)\n",
    "    df['altCount'] = df['GEN[*].AD'].str.split(\",\").str[1].astype(int)\n",
    "    df = df[(df['refCount']>=2) & (df['altCount']>=2) & (df['refCount']+df['altCount'] >=10)]\n",
    "    ####\n",
    "    df['term'] = df['CHROM'] + \":\" + df['POS'].astype(str)\n",
    "    df_heter = df[df['GEN[*].GT'] == \"0/1\"]\n",
    "    df_homo = df[df['GEN[*].GT'] == \"1/1\"]\n",
    "    info_dict[sample_n]['heter'] = dict(zip(df_heter['term'], df_heter['GEN[*].AD']))\n",
    "    info_dict[sample_n]['homo'] = dict(zip(df_homo['term'], df_homo['GEN[*].AD']))\n",
    "#### \n",
    "print(info_dict['liver_IP_3']['heter']['chr1:14574']) # 24,8\n",
    "print(info_dict['liver_IP_3']['homo']['chr1:565870']) # 3,5597"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### query tagSNP acorss 90 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': ['placenta_IP_6', 'FrontalCortex_3', 'stomach_IP_4', 'Spleen_1', 'Spleen_3', 'placenta_IP_4', 'Heart_1', 'kidney_IP_4', 'lung_IP_4', 'muscle_IP_4'], 'AD': ['30,27', '27,6', '47,29', '23,7', '29,8', '32,18', '10,3', '25,9', '25,20', '28,16'], 'type': ['heter', 'heter', 'heter', 'heter', 'heter', 'heter', 'heter', 'heter', 'heter', 'heter']}\n"
     ]
    }
   ],
   "source": [
    "tagSNP = \"/Charles/project/ASm6A/ASm6A/functional_ASm6A/tagSNP/tagSNP.txt\"\n",
    "df = pd.read_table(tagSNP, header=None)\n",
    "df['term'] = df.iloc[:,0] + \":\" + df.iloc[:,1].astype(str)\n",
    "tagSNP_list = list(set(df['term'].tolist()))\n",
    "\n",
    "vcf_dir = \"/Charles/project/ASm6A/corrected_vcf/vcf/rename/extract_info/\"\n",
    "sample_list = [os.path.basename(x).split(\"_gatk.vcf\")[0] for x in glob.glob(\"%s/*_gatk.vcf\" % vcf_dir)]\n",
    "snp_dict = {}\n",
    "for tagSNP in tagSNP_list:\n",
    "    snp_dict[tagSNP] = {\"sample\": [], \"AD\": [], \"type\": []}\n",
    "    for sample in sample_list:\n",
    "        if tagSNP in info_dict[sample]['heter']:\n",
    "            snp_dict[tagSNP]['sample'].append(sample)\n",
    "            snp_dict[tagSNP]['AD'].append(info_dict[sample]['heter'][tagSNP])\n",
    "            snp_dict[tagSNP]['type'].append(\"heter\")\n",
    "        if tagSNP in info_dict[sample]['homo']:\n",
    "            snp_dict[tagSNP]['sample'].append(sample)\n",
    "            snp_dict[tagSNP]['AD'].append(info_dict[sample]['homo'][tagSNP])\n",
    "            snp_dict[tagSNP]['type'].append(\"homo\")\n",
    "###\n",
    "print(snp_dict['chr7:128292658'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate concordance score\n",
    "##### The read count comes  from  AD tag contained in vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0027700831024930687, 0.40495867768595056, 0.0560941828254848, 0.28444444444444456, 0.32213294375456536, 0.07840000000000001, 0.28994082840236696, 0.22145328719723192, 0.01234567901234569, 0.07438016528925619]\n"
     ]
    }
   ],
   "source": [
    "#### concordance between genotype of candiate SNP\n",
    "#### The order of ref,alt are the same.  \n",
    "from collections import Counter\n",
    "\n",
    "def calculate_heter(refCount, altCount):\n",
    "    ar = int(refCount)/(int(refCount)+int(altCount))\n",
    "    d = abs(0.5-ar)\n",
    "    s = (d*d)/(0.5*0.5)\n",
    "    return s\n",
    "    \n",
    "def calculate_homo(refCount, altCount):\n",
    "    return 1-calculate_heter(refCount, altCount)\n",
    "\n",
    "score_dict = {}\n",
    "for snp, i_dict in snp_dict.items():\n",
    "    ad_list, type_list, score_list = i_dict['AD'], i_dict['type'], []\n",
    "    for i in range(len(ad_list)):\n",
    "        ref_count, alt_count = ad_list[i].split(\",\")\n",
    "        if type_list[i] == \"heter\":\n",
    "            score_list.append(calculate_heter(ref_count, alt_count))\n",
    "        elif type_list[i] == \"homo\":\n",
    "            score_list.append(calculate_homo(ref_count, alt_count))\n",
    "    assert len(ad_list) == len(type_list) == len(score_list)\n",
    "    score_dict[snp] = score_list\n",
    "print(score_dict['chr7:128292658'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hypothesis test (高斯混合模型)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn import mixture\n",
    "from sklearn.mixture import GaussianMixture\n",
    "%run smartFunctions.ipynb import distributeBins\n",
    "%run GMM_select_Peak.ipynb import calc_causalSNP\n",
    "\n",
    "for snp, si_list in score_dict.items():\n",
    "#     si_list = sub_dict['conc_score']\n",
    "    if len(si_list) >= 10:\n",
    "        calc_causalSNP(snp, si_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snv</th>\n",
       "      <th>peakX</th>\n",
       "      <th>zScore</th>\n",
       "      <th>Pvalue</th>\n",
       "      <th>nComp</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Stdevs</th>\n",
       "      <th>pns</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr19:44418824</td>\n",
       "      <td>0.169550</td>\n",
       "      <td>-inf;inf|-3863474004743760.0;1.892313798241841...</td>\n",
       "      <td>0.0;0.0|0.0;0.0|0.025275351524042273;0.0|NA;NA</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0744|0.1696|0.017|0.1289</td>\n",
       "      <td>0.0|0.0|0.0076|0.0151</td>\n",
       "      <td>2|2|5|3</td>\n",
       "      <td>0.2222|0.2222|0.5556|0.3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr15:31665443</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>-1.2000569850689293;77.96739121638797|NA;NA|NA...</td>\n",
       "      <td>0.2301172097886507;0.0|NA;NA|NA;NA|NA;NA</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0152|0.2925|0.5463|0.1227</td>\n",
       "      <td>0.0126|0.0132|0.0|0.0457</td>\n",
       "      <td>18|3|1|7</td>\n",
       "      <td>2.0|0.3333|0.1111|0.7778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr11:35641844</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>NA;NA|-1.0320091168319419;466.2223627495159|NA...</td>\n",
       "      <td>NA;NA|0.30206784664690856;0.0|NA;NA|0.00105216...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.25|0.0022|0.16|0.0442</td>\n",
       "      <td>0.0|0.0021|0.0|0.0135</td>\n",
       "      <td>1|5|1|3</td>\n",
       "      <td>0.1111|0.5556|0.1111|0.3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr9:129266187</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>NA;NA|NA;NA|-3140368188905484.5;2.512294551124...</td>\n",
       "      <td>NA;NA|NA;NA|0.0;0.0|0.32428291549358135;0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0574|0.16|0.1111|0.0114</td>\n",
       "      <td>0.0118|0.0|0.0|0.0116</td>\n",
       "      <td>4|1|2|6</td>\n",
       "      <td>0.4444|0.1111|0.2222|0.6667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr3:195456837</td>\n",
       "      <td>0.169550</td>\n",
       "      <td>-1.4565939836530997;7.133758837431445</td>\n",
       "      <td>0.14522848941276206;9.76643876869293e-13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1696</td>\n",
       "      <td>0.1164</td>\n",
       "      <td>12</td>\n",
       "      <td>1.3333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              snv     peakX  \\\n",
       "0  chr19:44418824  0.169550   \n",
       "1  chr15:31665443  0.014400   \n",
       "2  chr11:35641844  0.001189   \n",
       "3  chr9:129266187  0.111111   \n",
       "4  chr3:195456837  0.169550   \n",
       "\n",
       "                                              zScore  \\\n",
       "0  -inf;inf|-3863474004743760.0;1.892313798241841...   \n",
       "1  -1.2000569850689293;77.96739121638797|NA;NA|NA...   \n",
       "2  NA;NA|-1.0320091168319419;466.2223627495159|NA...   \n",
       "3  NA;NA|NA;NA|-3140368188905484.5;2.512294551124...   \n",
       "4              -1.4565939836530997;7.133758837431445   \n",
       "\n",
       "                                              Pvalue  nComp  \\\n",
       "0     0.0;0.0|0.0;0.0|0.025275351524042273;0.0|NA;NA      4   \n",
       "1           0.2301172097886507;0.0|NA;NA|NA;NA|NA;NA      4   \n",
       "2  NA;NA|0.30206784664690856;0.0|NA;NA|0.00105216...      4   \n",
       "3        NA;NA|NA;NA|0.0;0.0|0.32428291549358135;0.0      4   \n",
       "4           0.14522848941276206;9.76643876869293e-13      1   \n",
       "\n",
       "                          Mean                    Stdevs       pns  \\\n",
       "0   0.0744|0.1696|0.017|0.1289     0.0|0.0|0.0076|0.0151   2|2|5|3   \n",
       "1  0.0152|0.2925|0.5463|0.1227  0.0126|0.0132|0.0|0.0457  18|3|1|7   \n",
       "2      0.25|0.0022|0.16|0.0442     0.0|0.0021|0.0|0.0135   1|5|1|3   \n",
       "3    0.0574|0.16|0.1111|0.0114     0.0118|0.0|0.0|0.0116   4|1|2|6   \n",
       "4                       0.1696                    0.1164        12   \n",
       "\n",
       "                         ratio  \n",
       "0  0.2222|0.2222|0.5556|0.3333  \n",
       "1     2.0|0.3333|0.1111|0.7778  \n",
       "2  0.1111|0.5556|0.1111|0.3333  \n",
       "3  0.4444|0.1111|0.2222|0.6667  \n",
       "4                       1.3333  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### parse results\n",
    "in_file = \"/Charles/project/ASm6A/ASm6A/functional_ASm6A/GMM_results.txt\"\n",
    "df = pd.read_table(in_file, header=None, sep=\" \")\n",
    "df.columns = [\"snv\", \"peakX\", \"zScore\", \"Pvalue\", \"nComp\", \"Mean\", \"Stdevs\", \"pns\", \"ratio\"]\n",
    "df['peakX'] = df['peakX'].astype(float)\n",
    "df_sub = df[df['peakX'] > 0.5]\n",
    "# print(len(df_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_common_SNPs(snp_list):\n",
    "    snp_array = []\n",
    "    for i_sample in snp_list:\n",
    "        i_list = i_sample.split(\"@\")\n",
    "        snp_array.append(i_list)\n",
    "    sample_num = len(snp_array)\n",
    "    total_list, result_list = [], []\n",
    "    for i_list in snp_array:\n",
    "        total_list += [x.split(\"-\")[0] for x in i_list] ### only keep position info\n",
    "    count = Counter(total_list)\n",
    "    for snp, i_count in count.items():\n",
    "        if i_count == sample_num:\n",
    "            result_list.append(snp)\n",
    "    return snp_array, result_list\n",
    "\n",
    "def cal_concor_for_eachSNP(snp_array, comm_list):\n",
    "    index_list, geno_list = [], []\n",
    "    for i in range(len(snp_array)):\n",
    "        snp_line = \"@\".join(snp_array[i])\n",
    "        if snp in snp_line:\n",
    "            index_list.append(i)\n",
    "            genotype = snp_line.split(\"%s-\"%snp)[1].split(\"@\")[0]\n",
    "            geno_list.append(genotype)\n",
    "    raw_list = [ar_list[i] for i in index_list]\n",
    "    assert len(raw_list) == len(geno_list)\n",
    "    score_list = []\n",
    "    for i in range(len(raw_list)):\n",
    "        if len(set(geno_list[i].split(\"/\"))) > 1:\n",
    "            score_list.append(calculate_heter(raw_list[i]))\n",
    "        else:\n",
    "            score_list.append(calculate_homo(raw_list[i]))\n",
    "    return score_list, geno_list\n",
    "\n",
    "score_dict = {}\n",
    "for ASm6A, info_dict in term_dict.items():\n",
    "    snp_list, ar_list, sample_list = info_dict['SNP'], info_dict['AR'], info_dict['sample']\n",
    "    snp_array, comm_list = select_common_SNPs(snp_list)\n",
    "    for snp in comm_list:\n",
    "        score_dict[snp] = {\"conc_score\": [], \"genotype\": []}\n",
    "        score_list, geno_list = cal_concor_for_eachSNP(snp_array, comm_list)\n",
    "        score_dict[snp]['conc_score'] = score_list\n",
    "        score_dict[snp]['genotype'] = geno_list\n",
    "#\n",
    "score_dict['chr10:101152191']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
